{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
    "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "import ipyplot\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image specification\n",
    "img_rows,img_cols=64,64\n",
    "\n",
    "# Training data\n",
    "\n",
    "X_tr=[]           # variable to store entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4162 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "imshow() missing required argument 'mat' (pos 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-cdcb82a33797>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     27\u001B[0m             \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m     \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[0;31m#input_img = np.array(frames)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: imshow() missing required argument 'mat' (pos 2)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ls_path_4 = os.path.join(\"./data/Swiping Left\")\n",
    "listing_4 = os.listdir(ls_path_4)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for ls_4 in tqdm(listing_4):\n",
    "    listing_stop_4 = sorted(os.listdir(os.path.join(ls_path_4,ls_4)))\n",
    "\n",
    "    #print(ls)\n",
    "    #img_depth = len(listing_stop_3)\n",
    "    frames = []\n",
    "    img_depth=0\n",
    "    for imgs_4 in listing_stop_4:\n",
    "        if img_depth < 32:\n",
    "            img = os.path.join(os.path.join(ls_path_4,ls_4),imgs_4)\n",
    "            #ret, frame = cap.read()\n",
    "            frame = cv2.imread(img)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "            #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(gray)\n",
    "            img_depth=img_depth+1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cv2.imshow(frames[0])\n",
    "\n",
    "    #ipyplot.plot_images(frames, max_images=32, img_width=80)\n",
    "\n",
    "    input_img = np.array(frames)\n",
    "    #print (input_img.shape)\n",
    "    ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "    ipt=np.rollaxis(ipt,2,0)\n",
    "    #print (ipt.shape)\n",
    "    X_tr.append(ipt)\n",
    "    \n",
    "    counter = counter + 1\n",
    "    if counter >= 400:\n",
    "        break\n",
    "\n",
    "#X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "print (ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print (num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 399/4084 [00:03<00:29, 124.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64, 64, 3)\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ls_path_5 = os.path.join(\"./data/Swiping Right\")\n",
    "listing_5 = os.listdir(ls_path_5)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for ls_5 in tqdm(listing_5):\n",
    "    listing_stop_5 = sorted(os.listdir(os.path.join(ls_path_5,ls_5)))\n",
    "\n",
    "    #print(ls)\n",
    "    #img_depth = len(listing_stop_3)\n",
    "    frames = []\n",
    "    img_depth=0\n",
    "    for imgs_5 in listing_stop_5:\n",
    "        if img_depth < 32:\n",
    "            img = os.path.join(os.path.join(ls_path_5,ls_5),imgs_5)\n",
    "            #ret, frame = cap.read()\n",
    "            frame = cv2.imread(img)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "            #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(gray)\n",
    "            img_depth=img_depth+1\n",
    "        else:\n",
    "            break\n",
    "    input_img = np.array(frames)\n",
    "    #print (input_img.shape)\n",
    "    ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "    ipt=np.rollaxis(ipt,2,0)\n",
    "    #print (ipt.shape)\n",
    "    X_tr.append(ipt)\n",
    "    \n",
    "    counter = counter + 1\n",
    "    if counter >= 400:\n",
    "        break\n",
    "\n",
    "#X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "print (ipt.shape)\n",
    "num_samples = len(X_tr) \n",
    "print (num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 399/4278 [00:03<00:32, 120.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64, 64, 3)\n",
      "1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "counter = 0\n",
    "\n",
    "ls_path_6 = os.path.join(\"./data/No gesture\")\n",
    "listing_6 = os.listdir(ls_path_6)\n",
    "\n",
    "for ls_6 in tqdm(listing_6):\n",
    "    listing_stop_6 = sorted(os.listdir(os.path.join(ls_path_6,ls_6)))\n",
    "    #print(ls)\n",
    "    #img_depth = len(listing_stop_3)\n",
    "    frames = []\n",
    "    img_depth=0\n",
    "    for imgs_6 in listing_stop_6:\n",
    "        if img_depth < 32:\n",
    "            img = os.path.join(os.path.join(ls_path_6,ls_6),imgs_6)\n",
    "            #ret, frame = cap.read()\n",
    "            frame = cv2.imread(img)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "            #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(gray)\n",
    "            img_depth=img_depth+1\n",
    "        else:\n",
    "            break\n",
    "    input_img = np.array(frames)\n",
    "    #print (input_img.shape)\n",
    "    ipt=np.rollaxis(np.rollaxis(input_img,2,0),2,0)\n",
    "    ipt=np.rollaxis(ipt,2,0)\n",
    "    #print (ipt.shape)\n",
    "    X_tr.append(ipt)\n",
    "    \n",
    "    counter = counter + 1\n",
    "    if counter >= 400:\n",
    "        break\n",
    "\n",
    "#X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "print (ipt.shape)\n",
    "num_samples = len(X_tr) \n",
    "print (num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "\n",
    "num_samples = len(X_tr_array) \n",
    "print (num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.ones((num_samples,),dtype = int)\n",
    "label[0:399]= 0\n",
    "label[400:799] = 1\n",
    "label[800:1199] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape: (1200, 16, 64, 64, 3)\n",
      "(1200, 16, 64, 64, 3) train samples\n"
     ]
    }
   ],
   "source": [
    "img_depth = 32\n",
    "train_data = [X_tr_array,label]\n",
    "\n",
    "(X_train, y_train) = (train_data[0],train_data[1])\n",
    "print('X_Train shape:', X_train.shape)\n",
    "\n",
    "train_set = np.zeros((num_samples, img_depth, img_cols,img_rows,3))\n",
    "\n",
    "for h in range(num_samples):\n",
    "    train_set[h][:][:][:][:]=X_train[h,:,:,:]\n",
    "  \n",
    "\n",
    "patch_size = 32    # img_depth or number of frames used for each video\n",
    "\n",
    "print(train_set.shape, 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Training parameters\n",
    "\n",
    "\n",
    "nb_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.53923\n",
      "147.46077\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing\n",
    "\n",
    "train_set = train_set.astype('float32')\n",
    "print(np.mean(train_set))\n",
    "train_set -= np.mean(train_set)\n",
    "print(np.max(train_set))\n",
    "train_set /=np.max(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "weight_decay = 0.00005\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv3D(16,(3,3,3),\n",
    "                        input_shape=(patch_size, img_cols, img_rows, 3),\n",
    "                        activation='relu'))\n",
    "model.add(Conv3D(16,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2a_a', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(32,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2b_a', activation = 'relu'))\n",
    "model.add(Conv3D(32,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2b_b', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(64,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2c_a', activation = 'relu'))\n",
    "model.add(Conv3D(64,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2c_b', activation = 'relu'))\n",
    "model.add(Conv3D(64,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2c_c', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(128,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2d_a', activation = 'relu'))\n",
    "model.add(Conv3D(128,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2d_b', activation = 'relu'))\n",
    "model.add(Conv3D(128,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2d_c', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),\n",
    "                  strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm2d_2'))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),\n",
    "                  strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm2d_3'))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),\n",
    "                  strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm2d_4'))\n",
    "\n",
    "\n",
    "#model.add(MaxPooling3D(pool_size=(nb_pool[0], nb_pool[0], nb_pool[0])))\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling3D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes,kernel_initializer='normal'))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 14, 62, 62, 16)    1312      \n",
      "_________________________________________________________________\n",
      "Conv3D_2a_a (Conv3D)         (None, 14, 62, 62, 16)    6912      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 7, 31, 31, 16)     0         \n",
      "_________________________________________________________________\n",
      "Conv3D_2b_a (Conv3D)         (None, 7, 31, 31, 32)     13824     \n",
      "_________________________________________________________________\n",
      "Conv3D_2b_b (Conv3D)         (None, 7, 31, 31, 32)     27648     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 7, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "Conv3D_2c_a (Conv3D)         (None, 7, 15, 15, 64)     55296     \n",
      "_________________________________________________________________\n",
      "Conv3D_2c_b (Conv3D)         (None, 7, 15, 15, 64)     110592    \n",
      "_________________________________________________________________\n",
      "Conv3D_2c_c (Conv3D)         (None, 7, 15, 15, 64)     110592    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "Conv3D_2d_a (Conv3D)         (None, 7, 7, 7, 128)      221184    \n",
      "_________________________________________________________________\n",
      "Conv3D_2d_b (Conv3D)         (None, 7, 7, 7, 128)      442368    \n",
      "_________________________________________________________________\n",
      "Conv3D_2d_c (Conv3D)         (None, 7, 7, 7, 128)      442368    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 7, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "gatedclstm2d_2 (ConvLSTM2D)  (None, 7, 3, 3, 64)       442624    \n",
      "_________________________________________________________________\n",
      "gatedclstm2d_3 (ConvLSTM2D)  (None, 7, 3, 3, 64)       295168    \n",
      "_________________________________________________________________\n",
      "gatedclstm2d_4 (ConvLSTM2D)  (None, 7, 3, 3, 64)       295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,465,251\n",
      "Trainable params: 2,465,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shysa/PycharmProjects/test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = os.path.join(os.getcwd(),'saved_model')\n",
    "print(os.getcwd())\n",
    "model_name = \"3DCNN+3LSTM_64_6_jester\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor = 'val_acc', \n",
    "                            save_best_only=True, verbose=1)\n",
    "#earlystop\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=50, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.005,  momentum=0.9, nesterov=False)\n",
    "rms = RMSprop(decay=1e-6)\n",
    "ada = Adadelta(lr=0.1,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              #optimizer=ada,\n",
    "              #optimizer = Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_val_new, y_train_new,y_val_new = train_test_split(train_set, Y_train, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "30/30 [==============================] - 29s 663ms/step - loss: 1.3185 - acc: 0.2827 - val_loss: 1.3179 - val_acc: 0.3458\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.34583, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 2/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 1.3179 - acc: 0.3336 - val_loss: 1.3181 - val_acc: 0.3250\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.34583\n",
      "Epoch 3/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 1.3178 - acc: 0.3209 - val_loss: 1.3178 - val_acc: 0.2917\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.34583\n",
      "Epoch 4/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 1.3178 - acc: 0.3134 - val_loss: 1.3180 - val_acc: 0.3250\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.34583\n",
      "Epoch 5/300\n",
      "30/30 [==============================] - 18s 610ms/step - loss: 1.3177 - acc: 0.3156 - val_loss: 1.3180 - val_acc: 0.3250\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.34583\n",
      "Epoch 6/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 1.3176 - acc: 0.3250 - val_loss: 1.3180 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.34583\n",
      "Epoch 7/300\n",
      "30/30 [==============================] - 19s 618ms/step - loss: 1.3171 - acc: 0.3493 - val_loss: 1.3179 - val_acc: 0.3167\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.34583\n",
      "Epoch 8/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 1.3165 - acc: 0.3610 - val_loss: 1.3175 - val_acc: 0.3208\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.34583\n",
      "Epoch 9/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 1.3175 - acc: 0.3239 - val_loss: 1.3173 - val_acc: 0.3458\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.34583\n",
      "Epoch 10/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 1.3165 - acc: 0.3576 - val_loss: 1.3176 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.34583\n",
      "Epoch 11/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 1.3173 - acc: 0.3278 - val_loss: 1.3175 - val_acc: 0.3458\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.34583\n",
      "Epoch 12/300\n",
      "30/30 [==============================] - 19s 618ms/step - loss: 1.3167 - acc: 0.3469 - val_loss: 1.3173 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.34583\n",
      "Epoch 13/300\n",
      "30/30 [==============================] - 19s 632ms/step - loss: 1.3162 - acc: 0.3777 - val_loss: 1.3173 - val_acc: 0.3042\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.34583\n",
      "Epoch 14/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 1.3169 - acc: 0.3420 - val_loss: 1.3174 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.34583\n",
      "Epoch 15/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 1.3167 - acc: 0.3406 - val_loss: 1.3170 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.34583\n",
      "Epoch 16/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 1.3156 - acc: 0.3557 - val_loss: 1.3174 - val_acc: 0.3208\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.34583\n",
      "Epoch 17/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 1.3156 - acc: 0.3722 - val_loss: 1.3170 - val_acc: 0.3375\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.34583\n",
      "Epoch 18/300\n",
      "30/30 [==============================] - 19s 630ms/step - loss: 1.3167 - acc: 0.3339 - val_loss: 1.3168 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.34583\n",
      "Epoch 19/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 1.3151 - acc: 0.3763 - val_loss: 1.3168 - val_acc: 0.3208\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.34583\n",
      "Epoch 20/300\n",
      "30/30 [==============================] - 18s 616ms/step - loss: 1.3153 - acc: 0.3561 - val_loss: 1.3166 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.34583\n",
      "Epoch 21/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 1.3161 - acc: 0.3427 - val_loss: 1.3169 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.34583\n",
      "Epoch 22/300\n",
      "30/30 [==============================] - 19s 625ms/step - loss: 1.3151 - acc: 0.3439 - val_loss: 1.3173 - val_acc: 0.3208\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.34583\n",
      "Epoch 23/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 1.3158 - acc: 0.3408 - val_loss: 1.3162 - val_acc: 0.3542\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.34583 to 0.35417, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 24/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 1.3144 - acc: 0.3897 - val_loss: 1.3167 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.35417\n",
      "Epoch 25/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 1.3146 - acc: 0.3644 - val_loss: 1.3159 - val_acc: 0.3625\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.35417 to 0.36250, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 26/300\n",
      "30/30 [==============================] - 18s 616ms/step - loss: 1.3145 - acc: 0.3754 - val_loss: 1.3159 - val_acc: 0.3125\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.36250\n",
      "Epoch 27/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 1.3140 - acc: 0.3303 - val_loss: 1.3151 - val_acc: 0.3708\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.36250 to 0.37083, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 28/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 1.3137 - acc: 0.4302 - val_loss: 1.3147 - val_acc: 0.3917\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.37083 to 0.39167, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 29/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 1.3130 - acc: 0.3731 - val_loss: 1.3132 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.39167 to 0.41667, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 30/300\n",
      "30/30 [==============================] - 19s 619ms/step - loss: 1.3094 - acc: 0.4251 - val_loss: 1.3091 - val_acc: 0.4417\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.41667 to 0.44167, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 31/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 1.3058 - acc: 0.4540 - val_loss: 1.3010 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.44167\n",
      "Epoch 32/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 1.2941 - acc: 0.4867 - val_loss: 1.2774 - val_acc: 0.5542\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.44167 to 0.55417, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 33/300\n",
      "30/30 [==============================] - 19s 626ms/step - loss: 1.2437 - acc: 0.6352 - val_loss: 1.1561 - val_acc: 0.7167\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.55417 to 0.71667, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 34/300\n",
      "30/30 [==============================] - 18s 616ms/step - loss: 1.0975 - acc: 0.7618 - val_loss: 0.9169 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.71667 to 0.85000, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 35/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.9395 - acc: 0.7873 - val_loss: 0.8856 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.85000\n",
      "Epoch 36/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.8440 - acc: 0.7996 - val_loss: 0.7545 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.85000\n",
      "Epoch 37/300\n",
      "30/30 [==============================] - 19s 620ms/step - loss: 0.7273 - acc: 0.8420 - val_loss: 0.5783 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.85000 to 0.91250, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 38/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.6254 - acc: 0.8812 - val_loss: 0.5442 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.91250\n",
      "Epoch 39/300\n",
      "30/30 [==============================] - 19s 621ms/step - loss: 0.5926 - acc: 0.8867 - val_loss: 0.5899 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.91250\n",
      "Epoch 40/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.5634 - acc: 0.8973 - val_loss: 0.5623 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.91250\n",
      "Epoch 41/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.5455 - acc: 0.9017 - val_loss: 0.4971 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.91250 to 0.92083, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 42/300\n",
      "30/30 [==============================] - 19s 619ms/step - loss: 0.5418 - acc: 0.8896 - val_loss: 0.5124 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.92083\n",
      "Epoch 43/300\n",
      "30/30 [==============================] - 19s 633ms/step - loss: 0.6310 - acc: 0.8522 - val_loss: 0.5120 - val_acc: 0.9292\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.92083 to 0.92917, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 44/300\n",
      "30/30 [==============================] - 19s 626ms/step - loss: 0.5452 - acc: 0.8991 - val_loss: 0.4759 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.92917\n",
      "Epoch 45/300\n",
      "30/30 [==============================] - 19s 619ms/step - loss: 0.4907 - acc: 0.9094 - val_loss: 0.4571 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.92917 to 0.94167, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 46/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.4977 - acc: 0.9129 - val_loss: 0.4795 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.94167\n",
      "Epoch 47/300\n",
      "30/30 [==============================] - 18s 617ms/step - loss: 0.4943 - acc: 0.9147 - val_loss: 0.4767 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.94167\n",
      "Epoch 48/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.5753 - acc: 0.8823 - val_loss: 0.4760 - val_acc: 0.9292\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.94167\n",
      "Epoch 49/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.4877 - acc: 0.9315 - val_loss: 0.4176 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.94167 to 0.94583, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 50/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.4858 - acc: 0.9163 - val_loss: 0.4416 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.94583\n",
      "Epoch 51/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.4453 - acc: 0.9411 - val_loss: 0.4017 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.94583 to 0.95417, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 52/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.4145 - acc: 0.9475 - val_loss: 0.4293 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.95417\n",
      "Epoch 53/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.4122 - acc: 0.9502 - val_loss: 0.4519 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.95417\n",
      "Epoch 54/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.4094 - acc: 0.9429 - val_loss: 0.4423 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.95417\n",
      "Epoch 55/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.4727 - acc: 0.9103 - val_loss: 0.4600 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.95417\n",
      "Epoch 56/300\n",
      "30/30 [==============================] - 19s 624ms/step - loss: 0.4379 - acc: 0.9329 - val_loss: 0.4420 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.95417\n",
      "Epoch 57/300\n",
      "30/30 [==============================] - 19s 621ms/step - loss: 0.4337 - acc: 0.9351 - val_loss: 0.4014 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.95417\n",
      "Epoch 58/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.4014 - acc: 0.9449 - val_loss: 0.3993 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.95417 to 0.95833, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n",
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 59/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.3764 - acc: 0.9552 - val_loss: 0.4201 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.95833\n",
      "Epoch 60/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.4108 - acc: 0.9477 - val_loss: 0.4229 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.95833\n",
      "Epoch 61/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.4404 - acc: 0.9377 - val_loss: 0.3929 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.95833\n",
      "Epoch 62/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.3778 - acc: 0.9625 - val_loss: 0.4184 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.95833\n",
      "Epoch 63/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.3389 - acc: 0.9653 - val_loss: 0.4356 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.95833\n",
      "Epoch 64/300\n",
      "30/30 [==============================] - 19s 623ms/step - loss: 0.3794 - acc: 0.9529 - val_loss: 0.4086 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.95833\n",
      "Epoch 65/300\n",
      "30/30 [==============================] - 18s 616ms/step - loss: 0.3384 - acc: 0.9692 - val_loss: 0.4264 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.95833\n",
      "Epoch 66/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.3500 - acc: 0.9681 - val_loss: 0.4277 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.95833\n",
      "Epoch 67/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.3227 - acc: 0.9703 - val_loss: 0.4769 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.95833\n",
      "Epoch 68/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.3753 - acc: 0.9554 - val_loss: 0.4702 - val_acc: 0.9292\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.95833\n",
      "Epoch 69/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.4405 - acc: 0.9337 - val_loss: 0.4250 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.95833\n",
      "Epoch 70/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3786 - acc: 0.9606 - val_loss: 0.3997 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.95833 to 0.97083, saving model to /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/shysa/PycharmProjects/test/saved_model/3DCNN+3LSTM_64_6_jester/assets\n",
      "Epoch 71/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.3496 - acc: 0.9712 - val_loss: 0.4032 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 72/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3332 - acc: 0.9735 - val_loss: 0.4104 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.97083\n",
      "Epoch 73/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3323 - acc: 0.9699 - val_loss: 0.3866 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.97083\n",
      "Epoch 74/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.3195 - acc: 0.9753 - val_loss: 0.3886 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.97083\n",
      "Epoch 75/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3450 - acc: 0.9707 - val_loss: 0.3905 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.97083\n",
      "Epoch 76/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.3126 - acc: 0.9824 - val_loss: 0.3891 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.97083\n",
      "Epoch 77/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3171 - acc: 0.9781 - val_loss: 0.3918 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.97083\n",
      "Epoch 78/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3170 - acc: 0.9774 - val_loss: 0.3935 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.97083\n",
      "Epoch 79/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3093 - acc: 0.9786 - val_loss: 0.3941 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.97083\n",
      "Epoch 80/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.3282 - acc: 0.9759 - val_loss: 0.3953 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.97083\n",
      "Epoch 81/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2944 - acc: 0.9838 - val_loss: 0.3942 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.97083\n",
      "Epoch 82/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.3109 - acc: 0.9837 - val_loss: 0.3955 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.97083\n",
      "Epoch 83/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3138 - acc: 0.9825 - val_loss: 0.3950 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 84/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3222 - acc: 0.9790 - val_loss: 0.3962 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.97083\n",
      "Epoch 85/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2892 - acc: 0.9895 - val_loss: 0.3965 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.97083\n",
      "Epoch 86/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3029 - acc: 0.9825 - val_loss: 0.3970 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.97083\n",
      "Epoch 87/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.3108 - acc: 0.9839 - val_loss: 0.3957 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.97083\n",
      "Epoch 88/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3172 - acc: 0.9772 - val_loss: 0.4001 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.97083\n",
      "Epoch 89/300\n",
      "30/30 [==============================] - 19s 628ms/step - loss: 0.3072 - acc: 0.9854 - val_loss: 0.3959 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.97083\n",
      "Epoch 90/300\n",
      "30/30 [==============================] - 19s 625ms/step - loss: 0.3407 - acc: 0.9789 - val_loss: 0.3984 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.97083\n",
      "Epoch 91/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.2960 - acc: 0.9870 - val_loss: 0.3948 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.97083\n",
      "Epoch 92/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3127 - acc: 0.9832 - val_loss: 0.4019 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.97083\n",
      "Epoch 93/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.3029 - acc: 0.9837 - val_loss: 0.3991 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 94/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3254 - acc: 0.9764 - val_loss: 0.3976 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.97083\n",
      "Epoch 95/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.3248 - acc: 0.9846 - val_loss: 0.3965 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.97083\n",
      "Epoch 96/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3023 - acc: 0.9859 - val_loss: 0.4012 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.97083\n",
      "Epoch 97/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2909 - acc: 0.9866 - val_loss: 0.3962 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.97083\n",
      "Epoch 98/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2992 - acc: 0.9825 - val_loss: 0.4016 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.97083\n",
      "Epoch 99/300\n",
      "30/30 [==============================] - 18s 618ms/step - loss: 0.2928 - acc: 0.9882 - val_loss: 0.4000 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.97083\n",
      "Epoch 100/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.2700 - acc: 0.9939 - val_loss: 0.3970 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.97083\n",
      "Epoch 101/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3046 - acc: 0.9864 - val_loss: 0.3963 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.97083\n",
      "Epoch 102/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3340 - acc: 0.9816 - val_loss: 0.4017 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.97083\n",
      "Epoch 103/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3155 - acc: 0.9837 - val_loss: 0.3974 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 104/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3229 - acc: 0.9836 - val_loss: 0.4003 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.97083\n",
      "Epoch 105/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2692 - acc: 0.9927 - val_loss: 0.3977 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.97083\n",
      "Epoch 106/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2819 - acc: 0.9885 - val_loss: 0.3935 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.97083\n",
      "Epoch 107/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3073 - acc: 0.9828 - val_loss: 0.4058 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.97083\n",
      "Epoch 108/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3169 - acc: 0.9805 - val_loss: 0.3995 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.97083\n",
      "Epoch 109/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2904 - acc: 0.9869 - val_loss: 0.4006 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.97083\n",
      "Epoch 110/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2761 - acc: 0.9915 - val_loss: 0.4067 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.97083\n",
      "Epoch 111/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2893 - acc: 0.9882 - val_loss: 0.3987 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.97083\n",
      "Epoch 112/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2715 - acc: 0.9912 - val_loss: 0.3958 - val_acc: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00112: val_acc did not improve from 0.97083\n",
      "Epoch 113/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.2912 - acc: 0.9887 - val_loss: 0.4029 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 114/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2698 - acc: 0.9917 - val_loss: 0.4034 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.97083\n",
      "Epoch 115/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2829 - acc: 0.9886 - val_loss: 0.4036 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.97083\n",
      "Epoch 116/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3031 - acc: 0.9826 - val_loss: 0.4044 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.97083\n",
      "Epoch 117/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.3139 - acc: 0.9780 - val_loss: 0.3983 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.97083\n",
      "Epoch 118/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.3072 - acc: 0.9835 - val_loss: 0.4132 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.97083\n",
      "Epoch 119/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.3031 - acc: 0.9792 - val_loss: 0.3979 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.97083\n",
      "Epoch 120/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2826 - acc: 0.9867 - val_loss: 0.3950 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.97083\n",
      "Epoch 121/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3046 - acc: 0.9817 - val_loss: 0.4096 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.97083\n",
      "Epoch 122/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2824 - acc: 0.9893 - val_loss: 0.4012 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.97083\n",
      "Epoch 123/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2812 - acc: 0.9861 - val_loss: 0.4035 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 124/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.3237 - acc: 0.9775 - val_loss: 0.4037 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.97083\n",
      "Epoch 125/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2843 - acc: 0.9875 - val_loss: 0.4006 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.97083\n",
      "Epoch 126/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2742 - acc: 0.9890 - val_loss: 0.4007 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.97083\n",
      "Epoch 127/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2825 - acc: 0.9864 - val_loss: 0.4026 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.97083\n",
      "Epoch 128/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2698 - acc: 0.9888 - val_loss: 0.4025 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.97083\n",
      "Epoch 129/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2589 - acc: 0.9937 - val_loss: 0.4056 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.97083\n",
      "Epoch 130/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2795 - acc: 0.9898 - val_loss: 0.4040 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.97083\n",
      "Epoch 131/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2680 - acc: 0.9916 - val_loss: 0.4206 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.97083\n",
      "Epoch 132/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2827 - acc: 0.9868 - val_loss: 0.4015 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.97083\n",
      "Epoch 133/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2778 - acc: 0.9891 - val_loss: 0.4064 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 134/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2757 - acc: 0.9890 - val_loss: 0.4047 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.97083\n",
      "Epoch 135/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2746 - acc: 0.9878 - val_loss: 0.4061 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.97083\n",
      "Epoch 136/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2992 - acc: 0.9849 - val_loss: 0.3916 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.97083\n",
      "Epoch 137/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2931 - acc: 0.9898 - val_loss: 0.3917 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.97083\n",
      "Epoch 138/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2671 - acc: 0.9908 - val_loss: 0.3991 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.97083\n",
      "Epoch 139/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2741 - acc: 0.9915 - val_loss: 0.4041 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.97083\n",
      "Epoch 140/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2890 - acc: 0.9868 - val_loss: 0.3962 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.97083\n",
      "Epoch 141/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2857 - acc: 0.9849 - val_loss: 0.4059 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.97083\n",
      "Epoch 142/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2841 - acc: 0.9866 - val_loss: 0.4068 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.97083\n",
      "Epoch 143/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2851 - acc: 0.9857 - val_loss: 0.4038 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 144/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2767 - acc: 0.9890 - val_loss: 0.4136 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.97083\n",
      "Epoch 145/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2453 - acc: 0.9947 - val_loss: 0.4409 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.97083\n",
      "Epoch 146/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2665 - acc: 0.9912 - val_loss: 0.4382 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.97083\n",
      "Epoch 147/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2906 - acc: 0.9869 - val_loss: 0.4115 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.97083\n",
      "Epoch 148/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2969 - acc: 0.9862 - val_loss: 0.4068 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.97083\n",
      "Epoch 149/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2835 - acc: 0.9873 - val_loss: 0.4087 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.97083\n",
      "Epoch 150/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2775 - acc: 0.9872 - val_loss: 0.4139 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.97083\n",
      "Epoch 151/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2611 - acc: 0.9932 - val_loss: 0.4188 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.97083\n",
      "Epoch 152/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.3086 - acc: 0.9809 - val_loss: 0.4080 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.97083\n",
      "Epoch 153/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2858 - acc: 0.9875 - val_loss: 0.4186 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 154/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2915 - acc: 0.9861 - val_loss: 0.4144 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.97083\n",
      "Epoch 155/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2749 - acc: 0.9887 - val_loss: 0.4135 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.97083\n",
      "Epoch 156/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2782 - acc: 0.9900 - val_loss: 0.4170 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.97083\n",
      "Epoch 157/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2507 - acc: 0.9960 - val_loss: 0.4329 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.97083\n",
      "Epoch 158/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2504 - acc: 0.9936 - val_loss: 0.4247 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.97083\n",
      "Epoch 159/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.2684 - acc: 0.9908 - val_loss: 0.4160 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.97083\n",
      "Epoch 160/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2830 - acc: 0.9898 - val_loss: 0.4177 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.97083\n",
      "Epoch 161/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2908 - acc: 0.9898 - val_loss: 0.4134 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.97083\n",
      "Epoch 162/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2743 - acc: 0.9873 - val_loss: 0.4153 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.97083\n",
      "Epoch 163/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2805 - acc: 0.9872 - val_loss: 0.4246 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 164/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2575 - acc: 0.9954 - val_loss: 0.4167 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.97083\n",
      "Epoch 165/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2632 - acc: 0.9897 - val_loss: 0.4021 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.97083\n",
      "Epoch 166/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2586 - acc: 0.9914 - val_loss: 0.4119 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.97083\n",
      "Epoch 167/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2570 - acc: 0.9950 - val_loss: 0.4538 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.97083\n",
      "Epoch 168/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2555 - acc: 0.9955 - val_loss: 0.4209 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.97083\n",
      "Epoch 169/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2441 - acc: 0.9970 - val_loss: 0.4134 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.97083\n",
      "Epoch 170/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2791 - acc: 0.9878 - val_loss: 0.4197 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.97083\n",
      "Epoch 171/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2523 - acc: 0.9954 - val_loss: 0.4172 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.97083\n",
      "Epoch 172/300\n",
      "30/30 [==============================] - 19s 621ms/step - loss: 0.2491 - acc: 0.9947 - val_loss: 0.4164 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.97083\n",
      "Epoch 173/300\n",
      "30/30 [==============================] - 19s 639ms/step - loss: 0.2438 - acc: 0.9960 - val_loss: 0.4159 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 174/300\n",
      "30/30 [==============================] - 19s 632ms/step - loss: 0.2651 - acc: 0.9930 - val_loss: 0.4361 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.97083\n",
      "Epoch 175/300\n",
      "30/30 [==============================] - 18s 616ms/step - loss: 0.2381 - acc: 0.9975 - val_loss: 0.4186 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.97083\n",
      "Epoch 176/300\n",
      "30/30 [==============================] - 19s 630ms/step - loss: 0.2492 - acc: 0.9962 - val_loss: 0.4191 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.97083\n",
      "Epoch 177/300\n",
      "30/30 [==============================] - 19s 643ms/step - loss: 0.2497 - acc: 0.9958 - val_loss: 0.4190 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.97083\n",
      "Epoch 178/300\n",
      "30/30 [==============================] - 19s 623ms/step - loss: 0.2339 - acc: 0.9980 - val_loss: 0.4090 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.97083\n",
      "Epoch 179/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.2396 - acc: 0.9957 - val_loss: 0.4179 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.97083\n",
      "Epoch 180/300\n",
      "30/30 [==============================] - 19s 618ms/step - loss: 0.2510 - acc: 0.9916 - val_loss: 0.4216 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.97083\n",
      "Epoch 181/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2726 - acc: 0.9867 - val_loss: 0.4153 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.97083\n",
      "Epoch 182/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2504 - acc: 0.9912 - val_loss: 0.4264 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.97083\n",
      "Epoch 183/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2468 - acc: 0.9964 - val_loss: 0.4599 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 184/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.2646 - acc: 0.9895 - val_loss: 0.4318 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.97083\n",
      "Epoch 185/300\n",
      "30/30 [==============================] - 19s 619ms/step - loss: 0.2459 - acc: 0.9954 - val_loss: 0.4408 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.97083\n",
      "Epoch 186/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2513 - acc: 0.9947 - val_loss: 0.4122 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.97083\n",
      "Epoch 187/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.2434 - acc: 0.9959 - val_loss: 0.4223 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.97083\n",
      "Epoch 188/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2393 - acc: 0.9977 - val_loss: 0.4391 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.97083\n",
      "Epoch 189/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2351 - acc: 0.9984 - val_loss: 0.4415 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.97083\n",
      "Epoch 190/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2424 - acc: 0.9965 - val_loss: 0.4362 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.97083\n",
      "Epoch 191/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2316 - acc: 0.9986 - val_loss: 0.4425 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.97083\n",
      "Epoch 192/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2357 - acc: 0.9981 - val_loss: 0.4413 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.97083\n",
      "Epoch 193/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.2350 - acc: 0.9983 - val_loss: 0.4414 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 194/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2353 - acc: 0.9984 - val_loss: 0.4429 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.97083\n",
      "Epoch 195/300\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.2252 - acc: 0.9995 - val_loss: 0.4471 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.97083\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 19s 622ms/step - loss: 0.2366 - acc: 0.9972 - val_loss: 0.4487 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.97083\n",
      "Epoch 197/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2291 - acc: 0.9991 - val_loss: 0.4464 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.97083\n",
      "Epoch 198/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2326 - acc: 0.9979 - val_loss: 0.4473 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.97083\n",
      "Epoch 199/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2291 - acc: 0.9988 - val_loss: 0.4471 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.97083\n",
      "Epoch 200/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2348 - acc: 0.9982 - val_loss: 0.4525 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.97083\n",
      "Epoch 201/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2378 - acc: 0.9978 - val_loss: 0.4526 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.97083\n",
      "Epoch 202/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2288 - acc: 0.9987 - val_loss: 0.4493 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.97083\n",
      "Epoch 203/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2373 - acc: 0.9979 - val_loss: 0.4540 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 204/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2329 - acc: 0.9979 - val_loss: 0.4513 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.97083\n",
      "Epoch 205/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2463 - acc: 0.9950 - val_loss: 0.4544 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.97083\n",
      "Epoch 206/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2386 - acc: 0.9975 - val_loss: 0.4532 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.97083\n",
      "Epoch 207/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2359 - acc: 0.9972 - val_loss: 0.5183 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.97083\n",
      "Epoch 208/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2545 - acc: 0.9926 - val_loss: 0.4476 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.97083\n",
      "Epoch 209/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2280 - acc: 0.9994 - val_loss: 0.4595 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.97083\n",
      "Epoch 210/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2318 - acc: 0.9983 - val_loss: 0.4562 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.97083\n",
      "Epoch 211/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2435 - acc: 0.9967 - val_loss: 0.4565 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.97083\n",
      "Epoch 212/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2312 - acc: 0.9982 - val_loss: 0.4597 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.97083\n",
      "Epoch 213/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2334 - acc: 0.9961 - val_loss: 0.4679 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 214/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2251 - acc: 0.9994 - val_loss: 0.4539 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.97083\n",
      "Epoch 215/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.2294 - acc: 0.9987 - val_loss: 0.5022 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.97083\n",
      "Epoch 216/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2356 - acc: 0.9977 - val_loss: 0.4653 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.97083\n",
      "Epoch 217/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2299 - acc: 0.9986 - val_loss: 0.4650 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.97083\n",
      "Epoch 218/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2284 - acc: 0.9990 - val_loss: 0.4730 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.97083\n",
      "Epoch 219/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2280 - acc: 0.9991 - val_loss: 0.4580 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.97083\n",
      "Epoch 220/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2237 - acc: 0.9998 - val_loss: 0.4611 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.97083\n",
      "Epoch 221/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2254 - acc: 0.9995 - val_loss: 0.4615 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.97083\n",
      "Epoch 222/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2351 - acc: 0.9980 - val_loss: 0.4612 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.97083\n",
      "Epoch 223/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2476 - acc: 0.9975 - val_loss: 0.4608 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 224/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2246 - acc: 0.9996 - val_loss: 0.4617 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.97083\n",
      "Epoch 225/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2256 - acc: 0.9993 - val_loss: 0.4621 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.97083\n",
      "Epoch 226/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2281 - acc: 0.9988 - val_loss: 0.4630 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.97083\n",
      "Epoch 227/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2222 - acc: 0.9998 - val_loss: 0.4635 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.97083\n",
      "Epoch 228/300\n",
      "30/30 [==============================] - 18s 610ms/step - loss: 0.2267 - acc: 0.9990 - val_loss: 0.4630 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.97083\n",
      "Epoch 229/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2282 - acc: 0.9991 - val_loss: 0.4629 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.97083\n",
      "Epoch 230/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2264 - acc: 0.9993 - val_loss: 0.4631 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.97083\n",
      "Epoch 231/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2220 - acc: 0.9998 - val_loss: 0.4641 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.97083\n",
      "Epoch 232/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2222 - acc: 0.9998 - val_loss: 0.4641 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.97083\n",
      "Epoch 233/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2218 - acc: 0.9998 - val_loss: 0.4648 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 234/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2221 - acc: 0.9996 - val_loss: 0.4645 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.97083\n",
      "Epoch 235/300\n",
      "30/30 [==============================] - 18s 610ms/step - loss: 0.2276 - acc: 0.9989 - val_loss: 0.4655 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.97083\n",
      "Epoch 236/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2281 - acc: 0.9991 - val_loss: 0.4656 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.97083\n",
      "Epoch 237/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2285 - acc: 0.9984 - val_loss: 0.4654 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.97083\n",
      "Epoch 238/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2224 - acc: 0.9997 - val_loss: 0.4657 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.97083\n",
      "Epoch 239/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2247 - acc: 0.9993 - val_loss: 0.4656 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.97083\n",
      "Epoch 240/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2240 - acc: 0.9994 - val_loss: 0.4670 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.97083\n",
      "Epoch 241/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2214 - acc: 0.9997 - val_loss: 0.4671 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.97083\n",
      "Epoch 242/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2240 - acc: 0.9995 - val_loss: 0.4671 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.97083\n",
      "Epoch 243/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2294 - acc: 0.9984 - val_loss: 0.4675 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 244/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2245 - acc: 0.9995 - val_loss: 0.4671 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.97083\n",
      "Epoch 245/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2211 - acc: 0.9999 - val_loss: 0.4678 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.97083\n",
      "Epoch 246/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2269 - acc: 0.9987 - val_loss: 0.4678 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.97083\n",
      "Epoch 247/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2261 - acc: 0.9991 - val_loss: 0.4684 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.97083\n",
      "Epoch 248/300\n",
      "30/30 [==============================] - 18s 615ms/step - loss: 0.2210 - acc: 0.9998 - val_loss: 0.4694 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.97083\n",
      "Epoch 249/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2329 - acc: 0.9982 - val_loss: 0.4695 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.97083\n",
      "Epoch 250/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2477 - acc: 0.9969 - val_loss: 0.4695 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.97083\n",
      "Epoch 251/300\n",
      "30/30 [==============================] - 19s 620ms/step - loss: 0.2320 - acc: 0.9980 - val_loss: 0.4705 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.97083\n",
      "Epoch 252/300\n",
      "30/30 [==============================] - 20s 656ms/step - loss: 0.2200 - acc: 0.9998 - val_loss: 0.4701 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.97083\n",
      "Epoch 253/300\n",
      "30/30 [==============================] - 18s 617ms/step - loss: 0.2294 - acc: 0.9984 - val_loss: 0.4704 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 254/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2243 - acc: 0.9993 - val_loss: 0.4701 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.97083\n",
      "Epoch 255/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2302 - acc: 0.9986 - val_loss: 0.4703 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.97083\n",
      "Epoch 256/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2452 - acc: 0.9969 - val_loss: 0.4707 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.97083\n",
      "Epoch 257/300\n",
      "30/30 [==============================] - 19s 627ms/step - loss: 0.2264 - acc: 0.9986 - val_loss: 0.4716 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.97083\n",
      "Epoch 258/300\n",
      "30/30 [==============================] - 19s 626ms/step - loss: 0.2258 - acc: 0.9987 - val_loss: 0.4712 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.97083\n",
      "Epoch 259/300\n",
      "30/30 [==============================] - 19s 627ms/step - loss: 0.2215 - acc: 0.9996 - val_loss: 0.4722 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.97083\n",
      "Epoch 260/300\n",
      "30/30 [==============================] - 19s 620ms/step - loss: 0.2258 - acc: 0.9988 - val_loss: 0.4718 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.97083\n",
      "Epoch 261/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2455 - acc: 0.9959 - val_loss: 0.4729 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.97083\n",
      "Epoch 262/300\n",
      "30/30 [==============================] - 19s 634ms/step - loss: 0.2214 - acc: 0.9997 - val_loss: 0.4719 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.97083\n",
      "Epoch 263/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2236 - acc: 0.9995 - val_loss: 0.4720 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 264/300\n",
      "30/30 [==============================] - 19s 621ms/step - loss: 0.2210 - acc: 0.9998 - val_loss: 0.4722 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.97083\n",
      "Epoch 265/300\n",
      "30/30 [==============================] - 19s 620ms/step - loss: 0.2204 - acc: 0.9999 - val_loss: 0.4725 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.97083\n",
      "Epoch 266/300\n",
      "30/30 [==============================] - 18s 610ms/step - loss: 0.2226 - acc: 0.9993 - val_loss: 0.4729 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.97083\n",
      "Epoch 267/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2236 - acc: 0.9992 - val_loss: 0.4735 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.97083\n",
      "Epoch 268/300\n",
      "30/30 [==============================] - 18s 610ms/step - loss: 0.2323 - acc: 0.9980 - val_loss: 0.4743 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.97083\n",
      "Epoch 269/300\n",
      "30/30 [==============================] - 19s 631ms/step - loss: 0.2376 - acc: 0.9969 - val_loss: 0.4745 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.97083\n",
      "Epoch 270/300\n",
      "30/30 [==============================] - 19s 622ms/step - loss: 0.2217 - acc: 0.9996 - val_loss: 0.4741 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.97083\n",
      "Epoch 271/300\n",
      "30/30 [==============================] - 38s 1s/step - loss: 0.2222 - acc: 0.9996 - val_loss: 0.4745 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.97083\n",
      "Epoch 272/300\n",
      "30/30 [==============================] - 18s 607ms/step - loss: 0.2209 - acc: 0.9997 - val_loss: 0.4745 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.97083\n",
      "Epoch 273/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2196 - acc: 0.9997 - val_loss: 0.4741 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 274/300\n",
      "30/30 [==============================] - 18s 607ms/step - loss: 0.2269 - acc: 0.9987 - val_loss: 0.4748 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.97083\n",
      "Epoch 275/300\n",
      "30/30 [==============================] - 18s 607ms/step - loss: 0.2255 - acc: 0.9988 - val_loss: 0.4751 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.97083\n",
      "Epoch 276/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2260 - acc: 0.9986 - val_loss: 0.4749 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.97083\n",
      "Epoch 277/300\n",
      "30/30 [==============================] - 18s 607ms/step - loss: 0.2229 - acc: 0.9994 - val_loss: 0.4756 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.97083\n",
      "Epoch 278/300\n",
      "30/30 [==============================] - 19s 647ms/step - loss: 0.2207 - acc: 0.9997 - val_loss: 0.4756 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.97083\n",
      "Epoch 279/300\n",
      "30/30 [==============================] - 19s 623ms/step - loss: 0.2304 - acc: 0.9984 - val_loss: 0.4753 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.97083\n",
      "Epoch 280/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 19s 640ms/step - loss: 0.2191 - acc: 0.9998 - val_loss: 0.4760 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.97083\n",
      "Epoch 281/300\n",
      "30/30 [==============================] - 18s 611ms/step - loss: 0.2320 - acc: 0.9969 - val_loss: 0.4764 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.97083\n",
      "Epoch 282/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2217 - acc: 0.9996 - val_loss: 0.4770 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.97083\n",
      "Epoch 283/300\n",
      "30/30 [==============================] - 18s 607ms/step - loss: 0.2199 - acc: 0.9998 - val_loss: 0.4769 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 284/300\n",
      "30/30 [==============================] - 18s 616ms/step - loss: 0.2268 - acc: 0.9988 - val_loss: 0.4769 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.97083\n",
      "Epoch 285/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2242 - acc: 0.9991 - val_loss: 0.4774 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.97083\n",
      "Epoch 286/300\n",
      "30/30 [==============================] - 18s 616ms/step - loss: 0.2248 - acc: 0.9986 - val_loss: 0.4779 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.97083\n",
      "Epoch 287/300\n",
      "30/30 [==============================] - 18s 610ms/step - loss: 0.2236 - acc: 0.9992 - val_loss: 0.4777 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.97083\n",
      "Epoch 288/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2233 - acc: 0.9992 - val_loss: 0.4786 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.97083\n",
      "Epoch 289/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2217 - acc: 0.9995 - val_loss: 0.4792 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.97083\n",
      "Epoch 290/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2199 - acc: 0.9997 - val_loss: 0.4788 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.97083\n",
      "Epoch 291/300\n",
      "30/30 [==============================] - 18s 608ms/step - loss: 0.2302 - acc: 0.9980 - val_loss: 0.4793 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.97083\n",
      "Epoch 292/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2336 - acc: 0.9978 - val_loss: 0.4792 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.97083\n",
      "Epoch 293/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2197 - acc: 0.9998 - val_loss: 0.4793 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.97083\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 0.0008333333333333334.\n",
      "Epoch 294/300\n",
      "30/30 [==============================] - 18s 613ms/step - loss: 0.2321 - acc: 0.9980 - val_loss: 0.4801 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.97083\n",
      "Epoch 295/300\n",
      "30/30 [==============================] - 18s 614ms/step - loss: 0.2206 - acc: 0.9996 - val_loss: 0.4798 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.97083\n",
      "Epoch 296/300\n",
      "30/30 [==============================] - 18s 609ms/step - loss: 0.2208 - acc: 0.9996 - val_loss: 0.4795 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.97083\n",
      "Epoch 297/300\n",
      "30/30 [==============================] - 18s 610ms/step - loss: 0.2198 - acc: 0.9998 - val_loss: 0.4801 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.97083\n",
      "Epoch 298/300\n",
      "30/30 [==============================] - 18s 612ms/step - loss: 0.2293 - acc: 0.9984 - val_loss: 0.4802 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.97083\n",
      "Epoch 299/300\n",
      "20/30 [===================>..........] - ETA: 5s - loss: 0.2280 - acc: 0.9982"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 300\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "                               cooldown=0, patience=10, min_lr=0.005/(2^4),verbose=1)\n",
    "hist = model.fit(\n",
    "    X_train_new,\n",
    "    y_train_new,\n",
    "    validation_data=(X_val_new,y_val_new),\n",
    "    batch_size=batch_size,\n",
    "    epochs = nb_epoch,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint,lr_reducer]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_accuracy\")\n",
    "plt.plot(val_acc, label=\"validation_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}